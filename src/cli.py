#!/usr/bin/env python3
"""
Knowledge Search CLI - ks

Natural language search for your knowledge base
"""

import click
import time
import os
import sys
from pathlib import Path

# src Î™®Îìà importÎ•º ÏúÑÌïú Í≤ΩÎ°ú Ï∂îÍ∞Ä
sys.path.insert(0, str(Path(__file__).parent))

from search import KnowledgeSearch
from ingest import KnowledgeIngest


@click.group()
@click.version_option(version='0.1.0')
def cli():
    """
    Knowledge Search - Semantic search for your documents
    
    Search your Obsidian vault, notes, and documents with natural language.
    """
    pass


@cli.command()
@click.argument('query')
@click.option('--limit', default=5, help='Number of results (default: 5)')
@click.option('--source', help='Filter by source (e.g., obsidian)')
@click.option('--author', help='Filter by author')
@click.option('--min-similarity', type=float, help='Minimum similarity % (default: from config)')
@click.option('--benchmark', is_flag=True, help='Show search timing')
@click.option('--format', type=click.Choice(['text', 'json']), default='text', help='Output format: text (preview) or json (full content for AI)')
def search(query, limit, source, author, min_similarity, benchmark, format):
    """
    Search your knowledge base
    
    Examples:
    
      ks search "project planning"
      
      ks search "task priority" --limit 10
      
      ks search "meeting notes" --author John
    """
    try:
        # KnowledgeSearch Ï¥àÍ∏∞Ìôî
        config_path = Path(__file__).parent.parent / 'config.json'
        ks = KnowledgeSearch(str(config_path))
        
        # Í≤ÄÏÉâ Ïã§Ìñâ
        start = time.time()
        results = ks.search(
            query, 
            limit=limit, 
            source=source, 
            author=author,
            min_similarity=min_similarity
        )
        elapsed = time.time() - start
        
        # JSON Ï∂úÎ†• (AIÏö© - Ï†ÑÏ≤¥ ÎÇ¥Ïö© Ìè¨Ìï®)
        if format == 'json':
            import json
            output = {
                'query': query,
                'count': len(results),
                'results': results,
                'elapsed_ms': round(elapsed * 1000, 1) if benchmark else None
            }
            click.echo(json.dumps(output, ensure_ascii=False, indent=2))
            return
        
        # ÌÖçÏä§Ìä∏ Ï∂úÎ†• (ÏÇ¨ÎûåÏö© - PreviewÎßå)
        if not results:
            click.echo("‚ùå No results found.")
            click.echo(f"\nüí° Tips:")
            click.echo(f"  - Try different keywords")
            click.echo(f"  - Lower --min-similarity value")
            return
        
        click.echo(f"üîç Search results for '{query}' ({len(results)} found):\n")
        
        for i, result in enumerate(results, 1):
            # Ïú†ÏÇ¨ÎèÑÏóê Îî∞Î•∏ Ïù¥Î™®ÏßÄ
            if result['similarity'] >= 80:
                emoji = 'üéØ'
            elif result['similarity'] >= 60:
                emoji = '‚úÖ'
            else:
                emoji = 'üìÑ'
            
            click.echo(f"{emoji} [{i}] {result['path']}")
            click.echo(f"    Similarity: {result['similarity']}%")
            click.echo(f"    Author: {result['author']} | Source: {result['source']}")
            
            # ÌÖçÏä§Ìä∏ ÎØ∏Î¶¨Î≥¥Í∏∞ (Ïã§Ï†ú ÎÇ¥Ïö©Îßå ÌëúÏãú)
            text = result.get('text', '')
            if text:
                import re
                
                # HTML ÌÉúÍ∑∏ Ï†úÍ±∞
                clean_text = re.sub(r'<[^>]+>', '\n', text)
                
                # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìå®ÌÑ¥ Ï†úÍ±∞
                clean_text = re.sub(r'Category:.*?\n', '', clean_text)
                clean_text = re.sub(r'Created:.*?\n', '', clean_text)
                clean_text = re.sub(r'Modified:.*?\n', '', clean_text)
                clean_text = re.sub(r'^#.*?\n', '', clean_text, flags=re.MULTILINE)
                clean_text = re.sub(r'^---+\s*\n', '', clean_text, flags=re.MULTILINE)
                
                # Í≥µÎ∞± Ï†ïÎ¶¨
                clean_text = re.sub(r'\n\s*\n+', '\n', clean_text)
                clean_text = clean_text.strip()
                
                # Ï≤´ 3Í∞ú Ìï≠Î™© Ï∂îÏ∂ú (Ïã§Ï†ú ÎÇ¥Ïö©)
                lines = [l.strip() for l in clean_text.split('\n') if l.strip()]
                preview_items = lines[:5] if lines else []
                
                if preview_items:
                    preview_text = ', '.join(preview_items)
                    if len(preview_text) > 150:
                        preview_text = preview_text[:150] + '...'
                    click.echo(f"    Preview: {preview_text}")
                else:
                    # Ìè¥Î∞±: ÏõêÎ≥∏ ÌÖçÏä§Ìä∏ÏóêÏÑú 300Ïûê Ïù¥ÌõÑ 150Ïûê
                    fallback = text[300:450] if len(text) > 300 else text[:150]
                    click.echo(f"    Preview: {fallback}...")
            
            click.echo()
        
        # Î≤§ÏπòÎßàÌÅ¨ Ï†ïÎ≥¥
        if benchmark:
            click.echo(f"‚è±Ô∏è  Search time: {elapsed*1000:.0f}ms")
            click.echo(f"üìä Average similarity: {sum(r['similarity'] for r in results) / len(results):.1f}%")
    
    except FileNotFoundError:
        click.echo("‚ùå config.json not found.")
        click.echo("   Check your installation directory")
        sys.exit(1)
    except Exception as e:
        click.echo(f"‚ùå Error: {e}")
        if '--debug' in sys.argv:
            import traceback
            traceback.print_exc()
        sys.exit(1)


@cli.command()
def status():
    """
    Show index status
    
    Display total documents, source distribution, etc.
    """
    try:
        config_path = Path(__file__).parent.parent / 'config.json'
        ks = KnowledgeSearch(str(config_path))
        
        # Ï¥ù Î¨∏ÏÑú Ïàò
        result = ks.supabase.table("embeddings").select("*", count='exact').execute()
        total = result.count
        
        click.echo("üìä Knowledge Search Status\n")
        click.echo(f"Total documents: {total}")
        
        if total > 0:
            # ÏÜåÏä§Î≥Ñ ÌÜµÍ≥Ñ
            sources = {}
            authors = {}
            for doc in result.data:
                meta = doc.get('metadata', {})
                source = meta.get('source', 'unknown')
                author = meta.get('author', 'unknown')
                
                sources[source] = sources.get(source, 0) + 1
                authors[author] = authors.get(author, 0) + 1
            
            click.echo("\nBy source:")
            for source, count in sorted(sources.items(), key=lambda x: -x[1]):
                click.echo(f"  {source}: {count}")
            
            click.echo("\nBy author:")
            for author, count in sorted(authors.items(), key=lambda x: -x[1]):
                click.echo(f"  {author}: {count}")
        
        click.echo("\n‚úÖ System operational")
    
    except Exception as e:
        click.echo(f"‚ùå Error: {e}")
        sys.exit(1)


@cli.command()
@click.argument('folder')
@click.option('--source', default='obsidian', help='Source name')
@click.option('--author', default='unknown', help='Author name')
def ingest(folder, source, author):
    """
    Index documents from a folder
    
    Examples:
    
      ks ingest Projects
      
      ks ingest Notes/Work --author John
    """
    try:
        config_path = Path(__file__).parent.parent / 'config.json'
        ingestor = KnowledgeIngest(str(config_path))
        
        click.echo(f"üì• Indexing folder: {folder}\n")
        ingestor.ingest_folder(folder, source=source, author=author)
        click.echo("\n‚úÖ Indexing complete!")
    
    except Exception as e:
        click.echo(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    cli()
